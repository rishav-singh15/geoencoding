{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc597830",
   "metadata": {},
   "source": [
    "New logic for landmark similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189dd055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests pandas time tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e5d47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 geocoded:  atur park basant garden chembur mumbai  400071 -> (19.0514337, 72.9045968)\n",
      "2/10 geocoded: tilak road opp bikaji ghatkopare 400077 -> (19.0829313, 72.90709509999999)\n",
      "3/10 geocoded: station road vikhroliwest station road 400083 -> (19.1108928, 72.9270139)\n",
      "4/10 geocoded: oppshreyas cinema lbsmarg ghatkoparw 400082 -> (19.1284994, 72.9252816)\n",
      "5/10 geocoded: nr bhaji mandi kurlaw  400070 -> (19.065709, 72.8758792)\n",
      "6/10 geocoded: suleman khatri building  299f kurla west  kurla 400070 -> (19.0684302, 72.87566319999999)\n",
      "7/10 geocoded: shop no 03 vikas commercial centre chembur east near basant cinema 400074 -> (19.086383, 72.8889773)\n",
      "8/10 geocoded: shop no30dipak center safed pul saki naka mumbai 400072 -> (19.0985731, 72.8850052)\n",
      "9/10 geocoded: navketan building n g aacharya marg chembur east  400071 -> (19.0617585, 72.9009066)\n",
      "10/10 geocoded: chita camp mankhurd east 400088 -> (19.0472598, 72.9285969)\n",
      "Done! Output saved to geocoded_test_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"output_cleaned.csv\")  \n",
    "# Sample the first 10 rows for testing\n",
    "df_sample = df.head(10).copy()\n",
    "\n",
    "\n",
    "API_KEY = \"API_KEY\"  # replace this  \n",
    "\n",
    "df_sample[\"geocoded_latitude\"] = None\n",
    "df_sample[\"geocoded_longitude\"] = None\n",
    "\n",
    "\n",
    "def geocode_address(address, api_key):\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    params = {\n",
    "        \"address\": address,\n",
    "        \"key\": api_key\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result[\"status\"] == \"OK\":\n",
    "            location = result[\"results\"][0][\"geometry\"][\"location\"]\n",
    "            return location[\"lat\"], location[\"lng\"]\n",
    "    return None, None\n",
    "\n",
    "\n",
    "for i in range(len(df_sample)):\n",
    "    addr = df_sample.loc[i, \"address\"]\n",
    "    lat, lng = geocode_address(addr, API_KEY)\n",
    "    df_sample.loc[i, \"geocoded_latitude\"] = lat\n",
    "    df_sample.loc[i, \"geocoded_longitude\"] = lng\n",
    "    print(f\"{i+1}/10 geocoded: {addr} -> ({lat}, {lng})\")\n",
    "    time.sleep(1)  # Sleep to avoid hitting API rate limits\n",
    "\n",
    "df_sample.to_csv(\"geocoded_test_output.csv\", index=False)\n",
    "\n",
    "print(\"Done! Output saved to geocoded_test_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93035bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.48it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.80it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ High similarity landmark pairs: 3 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"geocoded_test_output.csv\")  # Replace with actual file name from previous step\n",
    "df = df.head(10)  # Only 10 rows for testing\n",
    "\n",
    "API_KEY = \"API_KEY\"  # replace this\n",
    "\n",
    "def get_landmarks(lat, lon, radius=50):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lon}\",\n",
    "        \"radius\": radius,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        return [place[\"name\"] for place in data.get(\"results\", [])]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching landmarks for ({lat}, {lon}): {e}\")\n",
    "        return []\n",
    "\n",
    "tqdm.pandas()\n",
    "df[\"orig_landmarks\"] = df.progress_apply(\n",
    "    lambda row: get_landmarks(row[\"latitude\"], row[\"longitude\"]), axis=1\n",
    ")\n",
    "df[\"geocoded_landmarks\"] = df.progress_apply(\n",
    "    lambda row: get_landmarks(row[\"geocoded_latitude\"], row[\"geocoded_longitude\"]), axis=1\n",
    ")\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_similarity(orig_list, geocoded_list):\n",
    "    if not orig_list or not geocoded_list:\n",
    "        return 0.0\n",
    "    try:\n",
    "        orig_text = \", \".join(orig_list)\n",
    "        geo_text = \", \".join(geocoded_list)\n",
    "\n",
    "        emb1 = model.encode(orig_text, convert_to_tensor=True)\n",
    "        emb2 = model.encode(geo_text, convert_to_tensor=True)\n",
    "\n",
    "        return util.pytorch_cos_sim(emb1, emb2).item()\n",
    "    except Exception as e:\n",
    "        print(f\"Similarity error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "df[\"landmark_similarity\"] = df.progress_apply(\n",
    "    lambda row: compute_similarity(row[\"orig_landmarks\"], row[\"geocoded_landmarks\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "high_sim_matches = df[df[\"landmark_similarity\"] > 0.75]\n",
    "print(f\"✔️ High similarity landmark pairs: {len(high_sim_matches)} out of {len(df)}\")\n",
    "\n",
    "df.to_csv(\"new_landmark_similarity_results_sample10.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91b7a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
