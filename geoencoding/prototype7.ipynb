{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf364c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92184949",
   "metadata": {},
   "source": [
    "10 rows trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2285f1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/p42j4t91737_2v19wfkt3sv80000gn/T/ipykernel_8700/317866638.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['reverse_geocoded_address'] = df.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File saved: output_test_10rows.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y5/p42j4t91737_2v19wfkt3sv80000gn/T/ipykernel_8700/317866638.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['new_latitude', 'new_longitude']] = df['reverse_geocoded_address'].apply(\n",
      "/var/folders/y5/p42j4t91737_2v19wfkt3sv80000gn/T/ipykernel_8700/317866638.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[['new_latitude', 'new_longitude']] = df['reverse_geocoded_address'].apply(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "df_full = pd.read_csv('output_cleaned.csv')  # original full dataset\n",
    "df = df_full.head(10)  # only take first 10 rows\n",
    "\n",
    "API_KEY = \"API_KEY\"  # replace this  \n",
    "\n",
    "def reverse_geocode(lat, lng):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?latlng={lat},{lng}&key={API_KEY}'\n",
    "    response = requests.get(url).json()\n",
    "    if response['status'] == 'OK' and response['results']:\n",
    "        return response['results'][0]['formatted_address']\n",
    "    return None\n",
    "\n",
    "def geocode(address):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={API_KEY}'\n",
    "    response = requests.get(url).json()\n",
    "    if response['status'] == 'OK' and response['results']:\n",
    "        location = response['results'][0]['geometry']['location']\n",
    "        return location['lat'], location['lng']\n",
    "    return None, None\n",
    "\n",
    "df['reverse_geocoded_address'] = df.apply(\n",
    "    lambda row: reverse_geocode(row['latitude'], row['longitude']), axis=1\n",
    ")\n",
    "time.sleep(1)\n",
    "\n",
    "df[['new_latitude', 'new_longitude']] = df['reverse_geocoded_address'].apply(\n",
    "    lambda addr: pd.Series(geocode(addr)) if pd.notnull(addr) else pd.Series([None, None])\n",
    ")\n",
    "df.to_csv('output_test_10rows.csv', index=False)\n",
    "print(\"✅ File saved: output_test_10rows.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662623ae",
   "metadata": {},
   "source": [
    "reverse geocoding entire cleaned document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3df19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Full file saved: output_with_geocoding.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "df = pd.read_csv('output_cleaned.csv')  # Replace with your full dataset\n",
    "\n",
    "API_KEY = \"API_KEY\"  # replace this  \n",
    "\n",
    "def reverse_geocode(lat, lng):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?latlng={lat},{lng}&key={API_KEY}'\n",
    "    response = requests.get(url).json()\n",
    "    if response['status'] == 'OK' and response['results']:\n",
    "        return response['results'][0]['formatted_address']\n",
    "    return None\n",
    "\n",
    "def geocode(address):\n",
    "    url = f'https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={API_KEY}'\n",
    "    response = requests.get(url).json()\n",
    "    if response['status'] == 'OK' and response['results']:\n",
    "        location = response['results'][0]['geometry']['location']\n",
    "        return location['lat'], location['lng']\n",
    "    return None, None\n",
    "\n",
    "\n",
    "df.loc[:, 'reverse_geocoded_address'] = df.apply(\n",
    "    lambda row: reverse_geocode(row['latitude'], row['longitude']), axis=1\n",
    ")\n",
    "time.sleep(1)  # Optional rate limit pause\n",
    "\n",
    "df[['new_latitude', 'new_longitude']] = df['reverse_geocoded_address'].apply(\n",
    "    lambda addr: pd.Series(geocode(addr)) if pd.notnull(addr) else pd.Series([None, None])\n",
    ")\n",
    "\n",
    "df.to_csv('output_with_geocoding.csv', index=False)\n",
    "print(\"✅ Full file saved: output_with_geocoding.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b354d93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: hdbscan in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.8.40)\n",
      "Requirement already satisfied: umap-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.5.9.post2)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hdbscan) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from umap-learn) (0.61.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers hdbscan umap-learn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf33bde9",
   "metadata": {},
   "source": [
    "HDBSCAN clustering match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce12e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c0d6355e7046f79b613ba1e0b82270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f6ef22386d480f92c9d2bcf6873397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing with UMAP...\n",
      "Clustering original addresses...\n",
      "Clustering reverse-geocoded addresses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating cosine similarity between address pairs...\n",
      "✅ Output saved to address_cluster_comparison.csv\n",
      "✔️ Matching clusters: 163 out of 3658\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from umap import UMAP\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"output_with_geocoding.csv\")\n",
    "df['address'] = df['address'].fillna('').astype(str)\n",
    "df['reverse_geocoded_address'] = df['reverse_geocoded_address'].fillna('').astype(str)\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Generating embeddings...\")\n",
    "embed_orig = model.encode(df['address'].tolist(), show_progress_bar=True)\n",
    "embed_rev = model.encode(df['reverse_geocoded_address'].tolist(), show_progress_bar=True)\n",
    "\n",
    "print(\"Reducing with UMAP...\")\n",
    "umap_model = UMAP(n_neighbors=15, n_components=15, metric='cosine')\n",
    "embed_orig_reduced = umap_model.fit_transform(embed_orig)\n",
    "embed_rev_reduced = umap_model.fit_transform(embed_rev)\n",
    "\n",
    "print(\"Clustering original addresses...\")\n",
    "cluster_orig = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=1, metric='euclidean').fit_predict(embed_orig_reduced)\n",
    "\n",
    "print(\"Clustering reverse-geocoded addresses...\")\n",
    "cluster_rev = hdbscan.HDBSCAN(min_cluster_size=3, min_samples=1, metric='euclidean').fit_predict(embed_rev_reduced)\n",
    "\n",
    "df['HDBSCAN_cluster_address'] = cluster_orig\n",
    "df['HDBSCAN_cluster_reverse'] = cluster_rev\n",
    "df['cluster_match'] = df['HDBSCAN_cluster_address'] == df['HDBSCAN_cluster_reverse']\n",
    "\n",
    "print(\"Calculating cosine similarity between address pairs...\")\n",
    "cos_sim = cosine_similarity(embed_orig, embed_rev)\n",
    "df['cosine_similarity'] = np.diag(cos_sim)\n",
    "\n",
    "df.to_csv(\"address_cluster_comparison.csv\", index=False)\n",
    "print(\"✅ Output saved to address_cluster_comparison.csv\")\n",
    "print(f\"✔️ Matching clusters: {df['cluster_match'].sum()} out of {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df737b",
   "metadata": {},
   "source": [
    "TF-IDF cosine similairty match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           address  \\\n",
      "0   atur park basant garden chembur mumbai  400071   \n",
      "1          tilak road opp bikaji ghatkopare 400077   \n",
      "2    station road vikhroliwest station road 400083   \n",
      "3      oppshreyas cinema lbsmarg ghatkoparw 400082   \n",
      "4                    nr bhaji mandi kurlaw  400070   \n",
      "\n",
      "                            reverse_geocoded_address  tfidf_cosine_sim  \\\n",
      "0  Shop No 11, 12, Sion - Trombay Rd, opp. Maitri...          0.507229   \n",
      "1  Shop No.4, Neelkanth Sadan, Hingwala Ln, opp. ...          0.049153   \n",
      "2  5, Station Rd, near Laxmi dairy, Lokamanya Nag...          0.086518   \n",
      "3  1, Lal Bahadur Shastri Marg, Sainath Nagar, Ni...          0.000000   \n",
      "4  Shop No 43 laxman road yadav market kurla bhaj...          0.066684   \n",
      "\n",
      "   likely_match  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "\n",
      "✔️ Matches above 0.75 similarity: 46 out of 3658\n",
      "✅ Output saved to address_TF-IDF_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(\"output_with_geocoding.csv\")\n",
    "\n",
    "df['address'] = df['address'].fillna('').astype(str)\n",
    "df['reverse_geocoded_address'] = df['reverse_geocoded_address'].fillna('').astype(str)\n",
    "\n",
    "all_addresses = df['address'].tolist() + df['reverse_geocoded_address'].tolist()\n",
    "\n",
    "# Fit TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))  # Use unigrams and bigrams\n",
    "tfidf_matrix = vectorizer.fit_transform(all_addresses)\n",
    "\n",
    "# Split the TF-IDF back\n",
    "original_tfidf = tfidf_matrix[:len(df)]\n",
    "reverse_tfidf = tfidf_matrix[len(df):]\n",
    "\n",
    "# Compute pairwise cosine similarity\n",
    "similarities = cosine_similarity(original_tfidf, reverse_tfidf)\n",
    "\n",
    "# Extract diagonal elements (same-row comparisons)\n",
    "df['tfidf_cosine_sim'] = [similarities[i, i] for i in range(len(df))]\n",
    "\n",
    "# Optional: Flag matches above a threshold\n",
    "df['likely_match'] = df['tfidf_cosine_sim'] >= 0.75\n",
    "\n",
    "print(df[['address', 'reverse_geocoded_address', 'tfidf_cosine_sim', 'likely_match']].head())\n",
    "print(f\"\\n✔️ Matches above 0.75 similarity: {df['likely_match'].sum()} out of {len(df)}\")\n",
    "\n",
    "df.to_csv(\"address_TF-IDF_comparison.csv\", index=False)\n",
    "print(\"✅ Output saved to address_TF-IDF_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582e07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
