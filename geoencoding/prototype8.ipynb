{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5667b836",
   "metadata": {},
   "source": [
    "Landmark Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23372976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: sentence-transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.1.0)\n",
      "Requirement already satisfied: hdbscan in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.8.40)\n",
      "Requirement already satisfied: umap-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.5.9.post2)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from hdbscan) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.51.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from umap-learn) (0.61.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from numba>=0.51.2->umap-learn) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas requests sentence-transformers hdbscan umap-learn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe65cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.69it/s]\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n",
      "100%|██████████| 10/10 [00:03<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ High similarity pairs (landmarks): 7 out of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"output_with_geocoding.csv\")\n",
    "df = df.head(10)  # Process only first 10 rows for testing\n",
    "\n",
    "API_KEY =\"API_KEY\"  # replace this \n",
    "\n",
    "def get_landmarks(lat, lon, radius=50):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lon}\",\n",
    "        \"radius\": radius,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        return [place[\"name\"] for place in data.get(\"results\", [])]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "tqdm.pandas()\n",
    "df[\"orig_landmarks\"] = df.progress_apply(lambda row: get_landmarks(row[\"latitude\"], row[\"longitude\"]), axis=1)\n",
    "df[\"rev_landmarks\"] = df.progress_apply(lambda row: get_landmarks(row[\"new_latitude\"], row[\"new_longitude\"]), axis=1)\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_similarity(orig_list, rev_list):\n",
    "    if not orig_list or not rev_list:\n",
    "        return 0.0\n",
    "    try:\n",
    "        # Join lists to make strings\n",
    "        orig_text = \", \".join(orig_list)\n",
    "        rev_text = \", \".join(rev_list)\n",
    "\n",
    "        emb1 = model.encode(orig_text, convert_to_tensor=True)\n",
    "        emb2 = model.encode(rev_text, convert_to_tensor=True)\n",
    "\n",
    "        sim_score = util.pytorch_cos_sim(emb1, emb2).item()\n",
    "        return sim_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "df[\"landmark_similarity\"] = df.progress_apply(\n",
    "    lambda row: compute_similarity(row[\"orig_landmarks\"], row[\"rev_landmarks\"]), axis=1\n",
    ")\n",
    "\n",
    "high_sim_matches = df[df[\"landmark_similarity\"] > 0.75]\n",
    "print(f\"✔️ High similarity pairs (landmarks): {len(high_sim_matches)} out of {len(df)}\")\n",
    "\n",
    "df.to_csv(\"landmark_similarity_results_sample10.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"output_with_geocoding.csv\")\n",
    "API_KEY = \"API_KEY\"  # replace this\n",
    "\n",
    "\n",
    "def get_landmarks(lat, lon, radius=50, retries=3):\n",
    "    url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lon}\",\n",
    "        \"radius\": radius,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if \"results\" in data:\n",
    "                    return [place[\"name\"] for place in data[\"results\"]]\n",
    "            else:\n",
    "                print(f\"Status code: {response.status_code}, sleeping...\")\n",
    "        except Exception as e:\n",
    "            print(f\"API error: {e}\")\n",
    "        time.sleep(2)  # Retry delay\n",
    "    return []\n",
    "\n",
    "\n",
    "tqdm.pandas(desc=\"Fetching Landmarks\")\n",
    "df[\"orig_landmarks\"] = df.progress_apply(lambda row: get_landmarks(row[\"latitude\"], row[\"longitude\"]), axis=1)\n",
    "df[\"rev_landmarks\"] = df.progress_apply(lambda row: get_landmarks(row[\"new_latitude\"], row[\"new_longitude\"]), axis=1)\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_similarity(orig_list, rev_list):\n",
    "    if not orig_list or not rev_list:\n",
    "        return 0.0\n",
    "    try:\n",
    "        emb1 = model.encode(\", \".join(orig_list), convert_to_tensor=True)\n",
    "        emb2 = model.encode(\", \".join(rev_list), convert_to_tensor=True)\n",
    "        return util.pytorch_cos_sim(emb1, emb2).item()\n",
    "    except Exception as e:\n",
    "        print(f\"Encoding error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "df[\"landmark_similarity\"] = df.progress_apply(\n",
    "    lambda row: compute_similarity(row[\"orig_landmarks\"], row[\"rev_landmarks\"]), axis=1\n",
    ")\n",
    "\n",
    "high_sim_matches = df[df[\"landmark_similarity\"] > 0.75]\n",
    "print(f\"✔️ High similarity matches: {len(high_sim_matches)} / {len(df)}\")\n",
    "\n",
    "# Save Results\n",
    "df.to_csv(\"landmark_similarity_results.csv\", index=False)\n",
    "print(\"✅ Results saved to landmark_similarity_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f394c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"output_with_geocoding.csv\")\n",
    "API_KEY = \"API_KEY\"  # replace this\n",
    "\n",
    "\n",
    "def get_landmarks(lat, lon, radius=50):\n",
    "    url = f\"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "    params = {\n",
    "        \"location\": f\"{lat},{lon}\",\n",
    "        \"radius\": radius,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        return [place[\"name\"] for place in data.get(\"results\", [])]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []\n",
    "\n",
    "df[\"orig_landmarks\"] = df.apply(lambda row: get_landmarks(row[\"latitude\"], row[\"longitude\"]), axis=1)\n",
    "df[\"rev_landmarks\"] = df.apply(lambda row: get_landmarks(row[\"new_latitude\"], row[\"new_longitude\"]), axis=1)\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-MiniLM-L6-v2\")\n",
    "\n",
    "def compute_similarity(orig_list, rev_list):\n",
    "    if not orig_list or not rev_list:\n",
    "        return 0.0\n",
    "    try:\n",
    "        # Join lists to make strings\n",
    "        orig_text = \", \".join(orig_list)\n",
    "        rev_text = \", \".join(rev_list)\n",
    "\n",
    "        emb1 = model.encode(orig_text, convert_to_tensor=True)\n",
    "        emb2 = model.encode(rev_text, convert_to_tensor=True)\n",
    "\n",
    "        sim_score = util.pytorch_cos_sim(emb1, emb2).item()\n",
    "        return sim_score\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "df[\"landmark_similarity\"] = df.progress_apply(lambda row: compute_similarity(row[\"orig_landmarks\"], row[\"rev_landmarks\"]), axis=1)\n",
    "\n",
    "high_sim_matches = df[df[\"landmark_similarity\"] > 0.75]\n",
    "print(f\"✔️ High similarity pairs (landmarks): {len(high_sim_matches)} out of {len(df)}\")\n",
    "\n",
    "df.to_csv(\"landmark_similarity_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
